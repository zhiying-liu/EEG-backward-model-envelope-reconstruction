{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca228ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "import librosa\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "#import 关于ica的一切\n",
    "from mne.preprocessing import ICA\n",
    "from mne_icalabel import label_components\n",
    "from matplotlib.cm import get_cmap\n",
    "\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "from scipy import signal # <<< 加上这一行来导入 signal 模块\n",
    "from typing import Union\n",
    "\n",
    "import numpy as np\n",
    "import h5py\n",
    "from scipy.signal import resample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fee49f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = r'D:\\A-BCI声音脑机接口\\4'\n",
    "\n",
    "eeg_files = sorted(glob.glob(os.path.join(root_dir, \"Data\", \"Session*\", \"*.vhdr\")))\n",
    "audio_files = sorted(glob.glob(os.path.join(root_dir, 'audio', 'M*.wav')))\n",
    "out_file = os.path.join(root_dir, 'my_backward_dataset1.hdf5')\n",
    "\n",
    "print(f\"找到 {len(eeg_files)} 个 EEG Session 文件\")\n",
    "print(f\"找到 {len(audio_files)} 个 Audio 文件\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a034fda7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32-channel mapping (to rename the channels)\n",
    "channel_map = {\n",
    "    '1': 'Fp1',\n",
    "    '2': 'Fp2',\n",
    "    '3': 'F7',\n",
    "    '4': 'F3',\n",
    "    '5': 'Fz',\n",
    "    '6': 'F4',\n",
    "    '7': 'F8',\n",
    "    '8': 'FC5',\n",
    "    '9': 'FC1',\n",
    "    '10': 'FC2',\n",
    "    '11': 'FC6',\n",
    "    '12': 'T7',\n",
    "    '13': 'C3',\n",
    "    '14': 'Cz',\n",
    "    '15': 'C4',\n",
    "    '16': 'T8',\n",
    "    '17': 'CP5',\n",
    "    '18': 'CP1',\n",
    "    '19': 'CP2',\n",
    "    '20': 'CP6',\n",
    "    '21': 'P7',\n",
    "    '22': 'P3',\n",
    "    '23': 'Pz',\n",
    "    '24': 'P4',\n",
    "    '25': 'P8',\n",
    "    '26': 'POz',\n",
    "    '27': 'O1',\n",
    "    '28': 'Oz',\n",
    "    '29': 'O2',\n",
    "    '30': 'FT9',\n",
    "    '31': 'FT10',\n",
    "    '32': 'TP9'\n",
    "}\n",
    "\n",
    "# Set montage\n",
    "montage = mne.channels.make_standard_montage('standard_1020')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713b43b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Alignment EEG (StimTrak) and Audio\n",
    "\n",
    "## Pad shorter signal with zeroes\n",
    "def pad_zeros_right(s, padding_length):\n",
    "    return np.pad(s, (0, padding_length), mode='constant', constant_values=0)\n",
    "\n",
    "def padding(a, b, pad_function=None):\n",
    "    if len(a) != len(b) and pad_function is None:\n",
    "        raise ValueError(f\"len(a)={len(a)} != len(b)={len(b)} and no pad_function provided\")\n",
    "    elif len(a) != len(b):\n",
    "        if len(a) < len(b):\n",
    "            a = pad_function(a, len(b) - len(a))\n",
    "        else:\n",
    "            b = pad_function(b, len(a) - len(b))\n",
    "    return a, b\n",
    "\n",
    "def crosscorrelation(ref, sig):\n",
    "    # ref = StimTrak/EEG-reference, sig = audio\n",
    "    c = correlate(ref, sig, mode='full')\n",
    "    lags = correlation_lags(len(ref), len(sig), mode='full')\n",
    "    return c, lags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0a378c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "   #提取audio文件的音频 用于后续的对齐\n",
    "    fs = 1000  # Hz\n",
    "\n",
    "    # Load audio wav-file\n",
    "    audios = []\n",
    "\n",
    "    for audionr in range(1, 16):\n",
    "\n",
    "        # Lade und resample direkt auf 1000 Hz\n",
    "        data, sr = librosa.load(audio_files, sr=fs)  # resample the audio data from 48kHz to 1kHz to align it with EEG\n",
    "\n",
    "        audios.append(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb14cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "###get envelope_list of audios (滤delta波，降采样至1000hz，用来加工hdf5文件)\n",
    "import numpy as np\n",
    "import librosa as lb\n",
    "from scipy import signal # <<< 加上这一行来导入 signal 模块\n",
    "from typing import Union\n",
    "\n",
    "# helper functions\n",
    "def get_envelope_from_hilbert(data: np.ndarray):\n",
    "    analytic_signal = signal.hilbert(data)\n",
    "    return np.abs(analytic_signal)\n",
    "\n",
    "def apply_butterworth_bandpass(data, order=4, cutoff_low=1, cutoff_high=20, fs=1000, axis=-1):\n",
    "    sos = signal.butter(N=order, Wn=[cutoff_low, cutoff_high], \n",
    "                        btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "    return signal.sosfiltfilt(sos, data, axis=axis)\n",
    "\n",
    "# ========== 音频预处理只做一次 ==========\n",
    "target_fs = 1000\n",
    "envelopes_list = []\n",
    "\n",
    "for i in range(1, 16):\n",
    "\n",
    "    # 1. 以原始采样率加载\n",
    "    stimuli, sr_orig = lb.load(audio_files, sr=None, mono=True)\n",
    "\n",
    "    # 2. 提取包络\n",
    "    envelope = get_envelope_from_hilbert(stimuli)\n",
    "\n",
    "    # 3. 滤波\n",
    "    delta_band_high = apply_butterworth_bandpass(\n",
    "        envelope, order=4, cutoff_low=1, cutoff_high=4, fs=sr_orig\n",
    "    )\n",
    "\n",
    "    # 4. 降采样到 EEG 采样率 1000 Hz\n",
    "    num_samples_1khz = int(len(delta_band_high) * target_fs / sr_orig)\n",
    "    delta_band_1khz = signal.resample(delta_band_high, num_samples_1khz)\n",
    "\n",
    "    # 5. 放到 list 里\n",
    "    envelopes_list.append(delta_band_1khz)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "790429b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 1. 初始化设置 ---\n",
    "\n",
    "# 如果你想每次运行代码都从头开始，先删除旧文件\n",
    "if os.path.exists(out_file):\n",
    "    os.remove(out_file) \n",
    "    print(f\"旧文件 {out_file} 已删除，准备创建新文件。\")\n",
    "\n",
    "# 定义起始 Subject ID (例如从 301 开始)\n",
    "current_subject_id = 301\n",
    "\n",
    "# --- 2. 开始遍历 Session (Session 循环) ---\n",
    "for sess_id, eeg_path in enumerate(eeg_files, start=1):\n",
    "    print(f\"\\n=== 处理 Session {sess_id} : {os.path.basename(eeg_path)} ===\")\n",
    "\n",
    "    # 读取数据\n",
    "    raw = mne.io.read_raw_brainvision(eeg_path, preload=True)\n",
    "    \n",
    "    # 提取 StimTrak (假设每个session都需要重新提取和对齐)\n",
    "    raw_data = raw.get_data()\n",
    "    stimtrak = raw_data[-1, :]\n",
    "    speech_stimulus_eeg = stimtrak\n",
    "\n",
    "    # --- Timeshifts 计算 (针对当前 Session) ---\n",
    "    # 注意：如果每个Session的音频对齐不同，这里需要重新计算\n",
    "    lag_samples_list = []\n",
    "    # timeshift_s_list = [] # 如果后面没用到可以注释掉\n",
    "\n",
    "    print(\"   正在计算 Audio Lags...\")\n",
    "    for i, audio in enumerate(audios, start=1):\n",
    "        audio_p, stim_p = padding(audio, speech_stimulus_eeg, pad_function=pad_zeros_right)\n",
    "        corr, lags = crosscorrelation(stim_p, audio_p)\n",
    "        peak_idx = np.argmax(np.abs(corr)) \n",
    "        lag_samples = lags[peak_idx]\n",
    "        # lag_seconds = lag_samples / fs\n",
    "        lag_samples_list.append(lag_samples)\n",
    "        # timeshift_s_list.append(lag_seconds)\n",
    "    \n",
    "    # 提取三个人的 Raw 对象\n",
    "    subj1_ch = [str(i) for i in range(1, 33)]\n",
    "    subj2_ch = [str(i) for i in range(33, 65)]\n",
    "    subj3_ch = [str(i) for i in range(65, 97)]\n",
    "\n",
    "    raw_list = [\n",
    "        raw.copy().pick_channels(subj1_ch),\n",
    "        raw.copy().pick_channels(subj2_ch),\n",
    "        raw.copy().pick_channels(subj3_ch)\n",
    "    ]\n",
    "\n",
    "    # --- 3. 遍历 Session 内的 3 个 Subject ---\n",
    "    for sub_idx, raw_sub in enumerate(raw_list):\n",
    "        \n",
    "        # 使用当前累计的 ID\n",
    "        print(f\"   正在处理 Subject {current_subject_id} (Session {sess_id} 的第 {sub_idx+1} 个人)...\")\n",
    "\n",
    "        # Set Montage & Rename (每个 Subject 独立进行)\n",
    "        raw_sub.rename_channels(channel_map)\n",
    "        raw_sub.set_montage(montage)\n",
    "\n",
    "        # --- 预处理 & ICA (你的原有逻辑) ---\n",
    "        # Highpass-filter for ICA\n",
    "        raw_ica = raw_sub.copy().filter(1., 100., fir_design='firwin', verbose=False) # 建议关掉 verbose 减少刷屏\n",
    "        raw_ica.set_eeg_reference('average', projection=False, verbose=False)\n",
    "\n",
    "        # ICA\n",
    "        ica = mne.preprocessing.ICA(n_components=15, method='infomax', fit_params=dict(extended=True), random_state=97, max_iter='auto')\n",
    "        ica.fit(raw_ica, verbose=False)\n",
    "\n",
    "        # ICLabel\n",
    "        labels = label_components(raw_ica, ica, method='iclabel')\n",
    "        # print(labels['labels']) # 可以注释掉减少刷屏\n",
    "        \n",
    "        artifact_comps = [i for i, label in enumerate(labels['labels']) if label in ['eye blink', 'muscle artifact']]\n",
    "        ica.exclude = artifact_comps\n",
    "\n",
    "        # Apply ICA\n",
    "        raw_clean = ica.apply(raw_sub.copy(), verbose=False)\n",
    "\n",
    "        # Notch & Filter\n",
    "        raw_clean.notch_filter(freqs=50, verbose=False)\n",
    "        delta = raw_clean.copy().filter(1., 4., fir_design='firwin', verbose=False)\n",
    "\n",
    "        # --- 准备切分数据 ---\n",
    "        eeg_mat = delta.get_data()\n",
    "        eeg_trials = []\n",
    "        env_trials = []\n",
    "\n",
    "        # 切分\n",
    "        for audio, lag in zip(envelopes_list, lag_samples_list):\n",
    "            L = len(audio)\n",
    "            start = int(lag)\n",
    "            stop = start + L\n",
    "            \n",
    "            # 简单的边界检查，防止 crashing\n",
    "            if stop > eeg_mat.shape[1]:\n",
    "                print(f\"Warning: Trial beyond data range for Sub {current_subject_id}\")\n",
    "                break \n",
    "                \n",
    "            eeg_trial = eeg_mat[:, start:stop]\n",
    "            env_trial = audio\n",
    "            \n",
    "            eeg_trials.append(eeg_trial)\n",
    "            env_trials.append(env_trial)\n",
    "\n",
    "        # --- 降采样 ---\n",
    "        current_fs = 1000\n",
    "        target_fs = 128\n",
    "        eeg_trials_low_fs = []\n",
    "        env_trials_low_fs = []\n",
    "        \n",
    "        # (这里使用你的降采样逻辑，为了简洁省略了中间 print)\n",
    "        for eeg_t in eeg_trials:\n",
    "            n_samples_new = int(eeg_t.shape[1] * target_fs / current_fs)\n",
    "            eeg_low = np.zeros((eeg_t.shape[0], n_samples_new))\n",
    "            for ch in range(eeg_t.shape[0]):\n",
    "                eeg_low[ch, :] = resample(eeg_t[ch, :], n_samples_new)\n",
    "            eeg_trials_low_fs.append(eeg_low)\n",
    "\n",
    "        for env_t in env_trials:\n",
    "            n_samples_new = int(env_t.shape[0] * target_fs / current_fs)\n",
    "            env_low = resample(env_t, n_samples_new)\n",
    "            env_trials_low_fs.append(env_low)\n",
    "\n",
    "        # --- 4. 写入 HDF5 (关键修改) ---\n",
    "        # 模式必须是 \"a\" (append)，否则会覆盖之前的数据\n",
    "        with h5py.File(out_file, \"a\") as f:\n",
    "            n_trials = len(eeg_trials_low_fs)\n",
    "            \n",
    "            print(f\"      -> 写入 Subject {current_subject_id} 到 HDF5...\")\n",
    "            \n",
    "            for t in range(n_trials):\n",
    "                trial_id = t + 1\n",
    "                \n",
    "                eeg_data = np.asarray(eeg_trials_low_fs[t])\n",
    "                env_data = np.asarray(env_trials_low_fs[t])\n",
    "\n",
    "                # 路径中使用 动态的 current_subject_id\n",
    "                eeg_path = f\"eeg/{current_subject_id}/{trial_id}\"\n",
    "                \n",
    "                # 防止重复写入报错（如果跑断了重跑）\n",
    "                if eeg_path in f:\n",
    "                    del f[eeg_path]\n",
    "\n",
    "                eeg_ds = f.create_dataset(eeg_path, data=eeg_data)\n",
    "\n",
    "                stim_code = f\"s{current_subject_id}_t{trial_id}\"\n",
    "                eeg_ds.attrs[\"stimulus\"] = stim_code\n",
    "\n",
    "                # Envelope (注意：如果不同人的 Envelope 是一样的，其实存一份就够了，但为了结构统一分别存也可以)\n",
    "                env_group_path = f\"stimulus_files/{stim_code}\"\n",
    "                if env_group_path in f: # 如果存在则先删除，防止报错\n",
    "                     del f[env_group_path]\n",
    "                \n",
    "                stim_group = f.require_group(env_group_path)\n",
    "                stim_group.create_dataset(\"attended_env\", data=env_data)\n",
    "\n",
    "        # --- 5. 循环末尾 ID 自增 ---\n",
    "        # 处理完一个人，ID + 1，为下一个人（无论是同Session还是下个Session）做准备\n",
    "        current_subject_id += 1\n",
    "\n",
    "print(f\"\\n所有 Session 处理完成。文件保存为: {out_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
