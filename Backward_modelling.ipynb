{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2b02f429",
   "metadata": {},
   "source": [
    "# üß†‚¨ÖÔ∏èüéß Decoding Acoustic Stimuli from EEG Data Using Backward Models\n",
    "\n",
    "In this notebook, we will learn the basics of **linear backward models**. Our goal is to find out how we can *reconstruct* the audiobooks participants were listening to, using only their brain signals!\n",
    "\n",
    "\n",
    " **A Note on Our Data**\n",
    "Just like in the previous notebook, we are working with **pre-processed and aligned data**. This means all the initial cleanup is already done:\n",
    "> \n",
    "* **EEG Data:** Filtered between 1-8 Hz.\n",
    "* **Speech Envelopes:** Pre-calculated and also filtered between 1-8 Hz.\n",
    "\n",
    "\n",
    "Also note, that for demonstration purposes, we only analyze data from a single subject (it makes the calculation much quicker)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6ea3b2-14b9-4250-86af-edca8528c904",
   "metadata": {},
   "source": [
    "# EEG Data Analysis: Seminar Notebook\n",
    "\n",
    "In this notebook, you will process your own EEG data step by step ‚Äî data that you recorded while listening to an audiobook.\n",
    "\n",
    "## Learning Objectives\n",
    "- Understand the EEG data structure  \n",
    "- Perform Independent Component Analysis (ICA)\n",
    "- Apply average referencing\n",
    "- Apply preprocessing: filtering (notch, frequency bands, causal vs. non-causal)  \n",
    "- Align EEG and audio data (StimTrak signal)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b849abad-93e8-4eaa-bf15-0c172634b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import numpy as np\n",
    "from scipy.signal import correlate, correlation_lags\n",
    "import librosa\n",
    "import mne\n",
    "from matplotlib import pyplot as plt\n",
    "%matplotlib qt\n",
    "\n",
    "from mne_icalabel import label_components\n",
    "from matplotlib.cm import get_cmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ed4c191-d8bb-4976-ab48-e3ca32faa523",
   "metadata": {},
   "source": [
    "## Rename the channels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f6ee37b-2308-4ce5-991f-4f45775f5be6",
   "metadata": {},
   "source": [
    "## Load and Visualize the raw EEG-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d38331-d3b2-49d6-b30e-dcfbd3e3ab86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 32-channel mapping (to rename the channels)\n",
    "channel_map = {\n",
    "    '1': 'Fp1',\n",
    "    '2': 'Fp2',\n",
    "    '3': 'F7',\n",
    "    '4': 'F3',\n",
    "    '5': 'Fz',\n",
    "    '6': 'F4',\n",
    "    '7': 'F8',\n",
    "    '8': 'FC5',\n",
    "    '9': 'FC1',\n",
    "    '10': 'FC2',\n",
    "    '11': 'FC6',\n",
    "    '12': 'T7',\n",
    "    '13': 'C3',\n",
    "    '14': 'Cz',\n",
    "    '15': 'C4',\n",
    "    '16': 'T8',\n",
    "    '17': 'CP5',\n",
    "    '18': 'CP1',\n",
    "    '19': 'CP2',\n",
    "    '20': 'CP6',\n",
    "    '21': 'P7',\n",
    "    '22': 'P3',\n",
    "    '23': 'Pz',\n",
    "    '24': 'P4',\n",
    "    '25': 'P8',\n",
    "    '26': 'POz',\n",
    "    '27': 'O1',\n",
    "    '28': 'Oz',\n",
    "    '29': 'O2',\n",
    "    '30': 'FT9',\n",
    "    '31': 'FT10',\n",
    "    '32': 'TP9'\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60287d19-90a4-4c88-b870-4769ae109859",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_and_set_montage(j_exp, raw_input, channel_map_32):\n",
    "    # 1. choose original channel range\n",
    "    # j=0: 1-32; j=1: 33-64; j=2: 65-96\n",
    "    start_ch_num = (j_exp * 32) + 1\n",
    "    end_ch_num = start_ch_num + 31 \n",
    "    \n",
    "    original_ch_names = [str(m) for m in range(start_ch_num, end_ch_num + 1)]\n",
    "    \n",
    "    # 2. choose channels (Á°Æ‰øù raw_input Â∑≤ÁªèÊòØ copy ËøáÁöÑ)\n",
    "    raw_processed = raw_input.pick_channels(original_ch_names)\n",
    "    \n",
    "    # 3. rename dictionary\n",
    "    rename_dict = {}\n",
    "    for i, original_name in enumerate(raw_processed.ch_names):\n",
    "        # i ‰ªé 0 Âà∞ 31„ÄÇ new_standard_key ÊòØÂ≠óÁ¨¶‰∏≤ '1' Âà∞ '32'\n",
    "        new_standard_key = str(i + 1)\n",
    "        rename_dict[original_name] = channel_map_32[new_standard_key]\n",
    "\n",
    "    raw_processed.rename_channels(rename_dict) \n",
    "    #4. set montage\n",
    "    montage = mne.channels.make_standard_montage('standard_1020')\n",
    "    raw_processed.set_montage(montage)\n",
    "    \n",
    "    return raw_processed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4572d30-2a08-4355-a731-29b76eeb4c58",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_ica(raw):\n",
    "    # Highpass-filter for ICA\n",
    "    raw_ica = raw.copy().filter(1., 100., fir_design='firwin')\n",
    "    \n",
    "    # Aet Average Reference\n",
    "    raw_ica.set_eeg_reference('average', projection=False)\n",
    "    # raw_ica.plot()\n",
    "\n",
    "    ica = mne.preprocessing.ICA(n_components=15, method='infomax', fit_params=dict(extended=True), random_state=97, max_iter='auto')\n",
    "    ica.fit(raw_ica)\n",
    "\n",
    "    # Classify components\n",
    "    labels = label_components(raw_ica, ica, method='iclabel')\n",
    "    print(labels['labels'])\n",
    "\n",
    "    # define artifact labels\n",
    "    artifact_labels = ['eye', 'muscle', 'heart', 'line_noise']\n",
    "    artifact_comps = [i for i, label in enumerate(labels['labels']) if label in ['eye blink', 'muscle artifact']]\n",
    "    ica.exclude = artifact_comps\n",
    "\n",
    "    # ica.plot_components(picks=artifact_comps, title='ICLabel: Artefakt-Komponenten')\n",
    "    # Apply ICA\n",
    "    raw_clean = ica.apply(raw.copy())\n",
    "    return raw_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a47065ad-8ada-43e6-af0e-b1bb9c94e9dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#change between inline and qt to see the plots in the notebook or in a separate window\n",
    "# %matplotlib inline #ÂõæÂÉèÁõ¥Êé•ÊòæÁ§∫Âú® Jupyter Notebook ÁöÑËæìÂá∫ÂçïÂÖÉÊ†º‰∏≠\n",
    "# %matplotlib qt #ÂºπÂá∫Áã¨Á´ãÁ™óÂè£\n",
    "from typing import Union\n",
    "import librosa as lb\n",
    "from scipy import signal\n",
    "\n",
    "\n",
    "#helper function creating the envelope by using the hilbert transform\n",
    "def get_envelope_from_hilbert(data: np.ndarray):\n",
    "    analytic_signal = signal.hilbert(data)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    return amplitude_envelope\n",
    "\n",
    "#helper function applying a Butterworth bandpass filter\n",
    "def apply_butterworth_bandpass(data: Union[np.ndarray], order=4, cutoff_low=1, cutoff_high=20, fs=1000, axis=-1):\n",
    "    sos = signal.butter(N=order, Wn=[cutoff_low, cutoff_high], btype=\"bandpass\", fs=fs, output=\"sos\")\n",
    "    filtered = signal.sosfiltfilt(sos, data, axis=axis)\n",
    "    return filtered\n",
    "\n",
    "## Pad shorter signal with zeroes\n",
    "def pad_zeros_right(s, padding_length):\n",
    "    return np.pad(s, (0, padding_length), mode='constant', constant_values=0)\n",
    "\n",
    "def padding(a, b, pad_function=None):\n",
    "    if len(a) != len(b) and pad_function is None:\n",
    "        raise ValueError(f\"len(a)={len(a)} != len(b)={len(b)} and no pad_function provided\")\n",
    "    elif len(a) != len(b):\n",
    "        if len(a) < len(b):\n",
    "            a = pad_function(a, len(b) - len(a))\n",
    "        else:\n",
    "            b = pad_function(b, len(a) - len(b))\n",
    "    return a, b\n",
    "\n",
    "def crosscorrelation(ref, sig):\n",
    "    # ref = StimTrak/EEG-reference, sig = audio\n",
    "    c = correlate(ref, sig, mode='full')\n",
    "    lags = correlation_lags(len(ref), len(sig), mode='full')\n",
    "    return c, lags"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13b3a8df-0590-467c-b3d4-cb3015b97366",
   "metadata": {},
   "source": [
    "## Load and Preprocessing EEG-Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d1a2c7a7-d873-4b6b-9039-23e3cdd29c50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed M01.wav, length=100656\n",
      "Processed M02.wav, length=110920\n",
      "Processed M03.wav, length=104384\n",
      "Processed M04.wav, length=94032\n",
      "Processed M05.wav, length=102328\n",
      "Processed M06.wav, length=54704\n",
      "Processed M07.wav, length=120072\n",
      "Processed M08.wav, length=118856\n",
      "Processed M09.wav, length=104656\n",
      "Processed M10.wav, length=119040\n",
      "Processed M11.wav, length=115840\n",
      "Processed M12.wav, length=123528\n",
      "Processed M13.wav, length=110192\n",
      "Processed M14.wav, length=113736\n",
      "Processed M15.wav, length=73176\n"
     ]
    }
   ],
   "source": [
    "# Load audio wav-file\n",
    "audios = []\n",
    "\n",
    "for i in range(1, 16):\n",
    "    filename = f\"/Users/zhiyingliu/Desktop/FAU/3-semester/audio-computer/submission/audio_stimuli/M{str(i).zfill(2)}.wav\"\n",
    "    \n",
    "    # Lade und resample direkt auf 1000 Hz\n",
    "    stimuli, sr = librosa.load(filename, sr=fs)  # resample the audio data from 48kHz to 1kHz to align it with EEG\n",
    "    \n",
    "    #apply the hilbert transform to our stimuli to get the envelope\n",
    "    envelope = get_envelope_from_hilbert(stimuli)\n",
    "\n",
    "    #filter the envelope to get the delta band (1 - 4 Hz)\n",
    "    delta_band = apply_butterworth_bandpass(envelope, order=4, cutoff_low=1, cutoff_high=4, fs=fs)\n",
    "    \n",
    "    #ÊâìÂç∞ËøõÂ∫¶\n",
    "    print(f'Processed M{str(i).zfill(2)}.wav, length={len(delta_band)}')\n",
    "\n",
    "    audios.append(delta_band)\n",
    "\n",
    "# print(delta_band_stimtrak.shape) #stimtrak\n",
    "# print(sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e66f1877-d272-4487-9be5-891eb89e50cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting parameters from /Users/zhiyingliu/Desktop/FAU/3-semester/audio-computer/submission/data/ABCI_Session1.vhdr...\n",
      "Setting channel info structure...\n",
      "Reading 0 ... 1649719  =      0.000 ...  1649.719 secs...\n",
      "   Ê≠£Âú®ËÆ°ÁÆó Audio Lags...\n",
      "NOTE: pick_channels() is a legacy function. New code should use inst.pick(...).\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 1e+02 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 100.00 Hz\n",
      "- Upper transition bandwidth: 25.00 Hz (-6 dB cutoff frequency: 112.50 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.5s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG channel type selected for re-referencing\n",
      "Applying average reference.\n",
      "Applying a custom ('EEG',) reference.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    1.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting ICA to data using 32 channels (please be patient, this may take a while)\n",
      "Selecting by number: 15 components\n",
      "Computing Extended Infomax ICA\n",
      "Fitting ICA took 202.9s.\n",
      "['other', 'muscle artifact', 'other', 'eye blink', 'brain', 'brain', 'other', 'other', 'other', 'muscle artifact', 'other', 'other', 'brain', 'muscle artifact', 'brain']\n",
      "Applying ICA to Raw instance\n",
      "    Transforming to ICA space (15 components)\n",
      "    Zeroing out 4 ICA components\n",
      "    Projecting back using 32 PCA components\n",
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-stop filter from 49 - 51 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandstop filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 49.38\n",
      "- Lower transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 49.12 Hz)\n",
      "- Upper passband edge: 50.62 Hz\n",
      "- Upper transition bandwidth: 0.50 Hz (-6 dB cutoff frequency: 50.88 Hz)\n",
      "- Filter length: 6601 samples (6.601 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.8s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtering raw data in 1 contiguous segment\n",
      "Setting up band-pass filter from 1 - 4 Hz\n",
      "\n",
      "FIR filter parameters\n",
      "---------------------\n",
      "Designing a one-pass, zero-phase, non-causal bandpass filter:\n",
      "- Windowed time-domain design (firwin) method\n",
      "- Hamming window with 0.0194 passband ripple and 53 dB stopband attenuation\n",
      "- Lower passband edge: 1.00\n",
      "- Lower transition bandwidth: 1.00 Hz (-6 dB cutoff frequency: 0.50 Hz)\n",
      "- Upper passband edge: 4.00 Hz\n",
      "- Upper transition bandwidth: 2.00 Hz (-6 dB cutoff frequency: 5.00 Hz)\n",
      "- Filter length: 3301 samples (3.301 s)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    1.5s finished\n",
      "[Parallel(n_jobs=1)]: Done  17 tasks      | elapsed:    0.7s\n",
      "[Parallel(n_jobs=1)]: Done  32 out of  32 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'resample' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 99\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[38;5;66;03m# ÈÄêÈÄöÈÅìËøõË°åÈôçÈááÊ†∑Ôºàresample ÈúÄË¶ÅÂØπÊó∂Èó¥ËΩ¥Êìç‰ΩúÔºâ\u001b[39;00m\n\u001b[1;32m     97\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m ch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(eeg_trial\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m     98\u001b[0m         \u001b[38;5;66;03m# resample ËøîÂõû (samples,)ÔºåÈúÄË¶ÅËµãÂÄºÁªô eeg_low_fs ÁöÑÂàó\u001b[39;00m\n\u001b[0;32m---> 99\u001b[0m         eeg_low_fs[ch, :] \u001b[38;5;241m=\u001b[39m \u001b[43mresample\u001b[49m(eeg_trial[ch, :], n_samples_new)\n\u001b[1;32m    101\u001b[0m     eeg_trials_low_fs\u001b[38;5;241m.\u001b[39mappend(eeg_low_fs)\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# --- 2. ÈôçÈááÊ†∑ Envelope ---\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'resample' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import h5py\n",
    "\n",
    "raw_data = []\n",
    "all_raws = []\n",
    "stimtrak = {}\n",
    "for session_i in range(1,6):\n",
    "    # ==== Load EEG data ====\n",
    "    eeg_path = f\"/Users/zhiyingliu/Desktop/FAU/3-semester/audio-computer/submission/data/ABCI_Session{session_i}.vhdr\"\n",
    "    raw_session = mne.io.read_raw_brainvision(eeg_path, preload=True)\n",
    "\n",
    "    stimtrak_data = raw_session.get_data()[-1,:] #105 channel\n",
    "    stimtrak[session_i] = stimtrak_data\n",
    "\n",
    "    # === Timeshifts ËÆ°ÁÆó (ÈíàÂØπÂΩìÂâç Session) ===\n",
    "    # Ê≥®ÊÑèÔºöÂ¶ÇÊûúÊØè‰∏™SessionÁöÑÈü≥È¢ëÂØπÈΩê‰∏çÂêåÔºåËøôÈáåÈúÄË¶ÅÈáçÊñ∞ËÆ°ÁÆó\n",
    "    lag_samples_list = []\n",
    "    # timeshift_s_list = [] # Â¶ÇÊûúÂêéÈù¢Ê≤°Áî®Âà∞ÂèØ‰ª•Ê≥®ÈáäÊéâ\n",
    "\n",
    "    envelope_stimtrak = get_envelope_from_hilbert(stimtrak_data)    \n",
    "    delta_band_stimtrak = apply_butterworth_bandpass(envelope_stimtrak, order=4, cutoff_low=1, cutoff_high=4, fs=fs)\n",
    "\n",
    "    print(\"   Ê≠£Âú®ËÆ°ÁÆó Audio Lags...\")\n",
    "    for i, audio in enumerate(audios, start=1):\n",
    "        audio_p, stim_p = padding(audio, delta_band_stimtrak, pad_function=pad_zeros_right)\n",
    "        corr, lags = crosscorrelation(stim_p, audio_p)\n",
    "        peak_idx = np.argmax(np.abs(corr)) \n",
    "        lag_samples = lags[peak_idx]\n",
    "        lag_samples_list.append(lag_samples)\n",
    "\n",
    "    # === pick only 32 channels ===\n",
    "    for j in range(3):\n",
    "        #ÂΩìÂâçsubject number\n",
    "        subject_id = (session_i-1)*3+j+1\n",
    "        \n",
    "        raw_exp = raw_session.copy()\n",
    "        raw_mon = process_and_set_montage(j, raw_exp, channel_map)\n",
    "        # ===ICA processing===\n",
    "        raw_clean = apply_ica(raw_mon)\n",
    "        \n",
    "        # ==Preprocessing: Filter EEG-Data==\n",
    "        # Notch-Filter at 50 Hz (power line)\n",
    "        raw_clean.notch_filter(freqs=50)\n",
    "        all_raws.append(raw_clean)\n",
    "        \n",
    "        # ==EEG Delta Band (1 - 4 Hz)==\n",
    "        delta = raw_clean.copy().filter(1., 4., fir_design='firwin')\n",
    "\n",
    "        \n",
    "        # ---------------------------------------------------------\n",
    "        # È¢ÑÂ§ÑÁêÜ‰ª£Á†ÅÂâçÈù¢Â∑≤ÁªèÁîüÊàê‰∫ÜÔºö\n",
    "        # raw_clean : np.array, shape (n_channels, n_samples_total)\n",
    "        # lag_samples_list : list of envelopes, each np.array(n_samples_i)\n",
    "        # timeshift_s_list : ÂèØÂøΩÁï•Ôºå‰∏çÁî®Â≠ò\n",
    "        # ---------------------------------------------------------\n",
    "        \n",
    "        out_file = \"backward_dataset.hdf5\"\n",
    "        \n",
    "        # ========== Step 1: Â∞Ü raw_clean Êåâ envelope ÈïøÂ∫¶ÂàáÂàÜ ==========\n",
    "        eeg_mat = delta.get_data()\n",
    "        eeg_trials = []\n",
    "        env_trials = []\n",
    "        \n",
    "        #ÂØπeegÊ†πÊçÆlag_sampling Ê†∑Êú¨ÁÇπ‰ΩçÁΩÆÂàÜ\n",
    "        for audio, lag in zip(audios, lag_samples_list):\n",
    "            L = len(audio)          # trial ÈïøÂ∫¶Ôºà1000 HzÔºâ\n",
    "            start = int(lag)\n",
    "            stop = start + L\n",
    "            eeg_trial = eeg_mat[:, start:stop]    # shape: (n_channels, L)\n",
    "            env_trial = audio              # envelope Áõ¥Êé•‰ΩøÁî®     # shape: (L,)\n",
    "        \n",
    "            eeg_trials.append(eeg_trial)\n",
    "            env_trials.append(env_trial)\n",
    "        \n",
    "        # print(len(eeg_trials), len(env_trials))\n",
    "        # print(eeg_trials[0].shape, env_trials[0].shape)\n",
    "        \n",
    "        # ========== Step 2: ÈôçÈááÊ†∑ ==========\n",
    "        \n",
    "        # --- ÂÅáËÆæÊÇ®Â∑≤ÁªèÂæóÂà∞‰∫ÜÂàáÂàÜÂêéÁöÑÈ´òÈááÊ†∑ÁéáÊï∞ÊçÆ ---\n",
    "        current_fs = 1000\n",
    "        target_fs = 128\n",
    "        eeg_trials_low_fs = []\n",
    "        env_trials_low_fs = []\n",
    "        \n",
    "        # --- 1. ÈôçÈááÊ†∑ EEG ---\n",
    "        for eeg_trial in eeg_trials:\n",
    "            n_samples_old = eeg_trial.shape[1]\n",
    "            \n",
    "            # ËÆ°ÁÆóÁõÆÊ†áÊ†∑Êú¨Êï∞\n",
    "            n_samples_new = int(n_samples_old * target_fs / current_fs)\n",
    "            \n",
    "            # ÂàùÂßãÂåñÈôçÈááÊ†∑ÂêéÁöÑ EEG Êï∞ÁªÑ\n",
    "            eeg_low_fs = np.zeros((eeg_trial.shape[0], n_samples_new))\n",
    "            \n",
    "            # ÈÄêÈÄöÈÅìËøõË°åÈôçÈááÊ†∑Ôºàresample ÈúÄË¶ÅÂØπÊó∂Èó¥ËΩ¥Êìç‰ΩúÔºâ\n",
    "            for ch in range(eeg_trial.shape[0]):\n",
    "                # resample ËøîÂõû (samples,)ÔºåÈúÄË¶ÅËµãÂÄºÁªô eeg_low_fs ÁöÑÂàó\n",
    "                eeg_low_fs[ch, :] = resample(eeg_trial[ch, :], n_samples_new)\n",
    "                \n",
    "            eeg_trials_low_fs.append(eeg_low_fs)\n",
    "        \n",
    "        # --- 2. ÈôçÈááÊ†∑ Envelope ---\n",
    "        for env_trial in env_trials:\n",
    "            # ÂΩ¢Áä∂ÊòØ (samples,)\n",
    "            n_samples_old = env_trial.shape[0]\n",
    "            \n",
    "            # ËÆ°ÁÆóÁõÆÊ†áÊ†∑Êú¨Êï∞ (‰∏é EEG Áõ∏Âêå)\n",
    "            n_samples_new = int(n_samples_old * target_fs / current_fs)\n",
    "            \n",
    "            # ÂØπ Envelope ËøõË°åÈôçÈááÊ†∑\n",
    "            env_low_fs = resample(env_trial, n_samples_new)\n",
    "            \n",
    "            env_trials_low_fs.append(env_low_fs)\n",
    "        \n",
    "        # Ê≠§Êó∂Ôºåeeg_trials_low_fs Âíå env_trials_low_fs Â∞±ÊòØÊÇ®ÈúÄË¶ÅÁöÑÈôçÈááÊ†∑ÂêéÁöÑÊï∞ÊçÆ\n",
    "        \n",
    "        # ========== Step 3: ÂÜôÂÖ•ÂÖºÂÆπÁöÑ HDF5 ==========\n",
    "        # Ê®°ÂºèÂøÖÈ°ªÊòØ \"a\" (append)ÔºåÂê¶Âàô‰ºöË¶ÜÁõñ‰πãÂâçÁöÑÊï∞ÊçÆ\n",
    "        with h5py.File(out_file, \"a\") as f:\n",
    "            n_trials = len(eeg_trials_low_fs)\n",
    "            print(f\"      -> ÂÜôÂÖ• Subject {subject_id} Âà∞ HDF5...\")\n",
    "\n",
    "        \n",
    "            for t in range(n_trials):\n",
    "                trial_id = t + 1\n",
    "        \n",
    "                eeg = np.asarray(eeg_trials_low_fs[t])   # (channels, samples) Â∞ÜËæìÂÖ•ËΩ¨Âåñ‰∏∫Êï∞ÁªÑ\n",
    "                env = np.asarray(env_trials_low_fs[t])   # (samples,)\n",
    "        \n",
    "                # ---- EEG ----\n",
    "                eeg_path = f\"eeg/{subject_id}/{trial_id}\"\n",
    "                eeg_ds = f.create_dataset(eeg_path, data=eeg)\n",
    "        \n",
    "                # ÁªôÊØè‰∏™ trial ‰∏Ä‰∏™ stimulus ÁºñÂè∑ÔºàËÄÅÂ∏à notebook ‰æùËµñËøô‰∏™Ôºâ\n",
    "                stim_code = f\"s{subject_id}_t{trial_id}\"\n",
    "                eeg_ds.attrs[\"stimulus\"] = stim_code\n",
    "        \n",
    "                # ---- envelope ----\n",
    "                stim_group = f.require_group(f\"stimulus_files/{stim_code}\")\n",
    "                stim_group.create_dataset(\"attended_env\", data=env)\n",
    "        \n",
    "        print(\"ÂÜôÂÖ•ÂÆåÊàêÔºö\", out_file)\n",
    "\n",
    "\n",
    "print(f\"\\nÊâÄÊúâ Session Â§ÑÁêÜÂÆåÊàê„ÄÇÊñá‰ª∂‰øùÂ≠ò‰∏∫: {out_file}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e09624e-b61c-47ca-9f17-0b1b2e0863f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(all_raws[0].info)\n",
    "print(all_raws[0].shape)\n",
    "print(stimtrak[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e80b99-72a4-414e-a914-5720b098f1b1",
   "metadata": {},
   "source": [
    "## Alignment: EEG & Audio (StimTrak)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "459a6d7f-4a7d-45e8-925c-c5bd06d3d398",
   "metadata": {},
   "source": [
    "## load audio file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4843fdac-622f-4dcd-9cdd-9c7d4912beeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/84/n7z137t10hl39svbf2_zh8g40000gn/T/ipykernel_8771/2345541329.py:10: MatplotlibDeprecationWarning: The get_cmap function was deprecated in Matplotlib 3.7 and will be removed in 3.11. Use ``matplotlib.colormaps[name]`` or ``matplotlib.colormaps.get_cmap()`` or ``pyplot.get_cmap()`` instead.\n",
      "  cmap = get_cmap('tab20')\n"
     ]
    }
   ],
   "source": [
    "# --- Overlay-Plot ---\n",
    "plt.figure(figsize=(14, 5))\n",
    "\n",
    "# plot StimTrak\n",
    "t_stim = np.arange(len(speech_stimulus_eeg)) / fs\n",
    "plt.plot(t_stim, speech_stimulus_eeg,\n",
    "         linewidth=1.5, alpha=1., label='StimTrak')\n",
    "\n",
    "# colormap for audios\n",
    "cmap = get_cmap('tab20')\n",
    "\n",
    "stim_amp = np.nanmax(np.abs(speech_stimulus_eeg))\n",
    "\n",
    "for i, (audio, lag_samples) in enumerate(zip(audios, lag_samples_list), start=1):\n",
    "    if np.max(np.abs(audio)) == 0:\n",
    "        scaled = audio\n",
    "    else:\n",
    "        scaled = (audio / np.max(np.abs(audio))) * (0.8 * stim_amp)\n",
    "\n",
    "    # align the audio part by shifting it according to computed lags\n",
    "    t_audio_shifted = (np.arange(len(audio)) + lag_samples) / fs\n",
    "\n",
    "    # color\n",
    "    color = cmap(i % cmap.N)\n",
    "\n",
    "    plt.plot(t_audio_shifted, scaled,\n",
    "             color=color, alpha=0.8,\n",
    "             label=f\"M{str(i).zfill(2)} ({lag_samples/fs:.3f}s)\")\n",
    "\n",
    "plt.xlabel(\"Time [s]\")\n",
    "plt.ylabel(\"Amplitude [a.u.]\")\n",
    "plt.title(\"StimTrak with aligned overlayed audio-signals\")\n",
    "plt.legend(ncol=3, fontsize=8)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ce65cff",
   "metadata": {},
   "source": [
    "# Decoding acoustic stimuli from EEG-data using backward models\n",
    "\n",
    "In this notebook, we will learn the basics of linear backward models and how we can reconstruct the presented audio books from brain signals.\n",
    "\n",
    "Again we are working with pre-processed and aligned data. This includes Filtering of EEG data and pre-calculated speech envelopes. Both 1-8Hz."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38e4e74c",
   "metadata": {},
   "source": [
    "# 1. Import necessary libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e9b7ac4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = \"/Users/zhiyingliu/Desktop/FAU/3-semester/audio-computer\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import sklearn\n",
    "if root_dir not in sys.path:\n",
    "    sys.path.append(root_dir)\n",
    "from models.ridge import Ridge\n",
    "import h5py\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pingouin as pg\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01d9ee42",
   "metadata": {},
   "source": [
    "# 2. Define constants and paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "e7407b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_file = os.path.join(root_dir, 'my_backward_dataset.hdf5')\n",
    "Fs = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62fd9de9",
   "metadata": {},
   "source": [
    "# 3. Load Data\n",
    "\n",
    "For more information on the data: look into the forward_modelling.ipynb Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "31289d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "# initial_subjects = [301]    # ‰Ω†ÁîüÊàêÁöÑ subject_id\n",
    "\n",
    "initial_subjects = list(range(301, 316))\n",
    "# subjects_to_remove = [310, 312, 320, 332]\n",
    "# subjects = [sub for sub in initial_subjects \n",
    "#             if sub not in subjects_to_remove]\n",
    "\n",
    "trials = list(range(1,16))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "46d1d36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_subject_data(subject, ica = False):\n",
    "    subject_eeg = []\n",
    "    subject_env = []\n",
    "    with h5py.File(data_file, 'r') as f:\n",
    "        for trial in trials: \n",
    "            eeg_path = f'eeg/{subject}/{trial}'\n",
    "            # eeg_ica_path = f'eeg_ica/{subject}/{trial}'\n",
    "            stim_code = f[eeg_path].attrs['stimulus']\n",
    "            env_attended_path = f'stimulus_files/{stim_code}/attended_env'\n",
    "            # if ica:\n",
    "            #     eeg = f[eeg_ica_path][:]\n",
    "            # else:\n",
    "            eeg = f[eeg_path][:]\n",
    "            # We drop the last two channels which are AUX channels (not EEG)\n",
    "            eeg = eeg[:31,:]\n",
    "            env_attended = f[env_attended_path][:]\n",
    "            subject_eeg.append(np.array(eeg))\n",
    "            subject_env.append(np.array(env_attended))\n",
    "    return subject_eeg, subject_env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "22bb86b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_indices(eeg, env, indices, test = False):\n",
    "\n",
    "    # Extract data for the given indices\n",
    "    eeg_data = [eeg[ind-1] for ind in indices]\n",
    "    env_data = [env[ind-1] for ind in indices]\n",
    "\n",
    "    if not test:\n",
    "        # Concatenate all trials into single arrays\n",
    "        eeg_data_array = np.hstack([eeg_data[i] for i in range(len(eeg_data))])\n",
    "        env_data_array = np.hstack([env_data[i] for i in range(len(env_data))])\n",
    "        env_data_array = env_data_array[np.newaxis,:]  # Add channel dimension\n",
    "    else:\n",
    "        eeg_data_array = eeg_data\n",
    "        env_data_array = [np.array(env_data[i])[np.newaxis,:] for i in range(len(env_data))]\n",
    "        #‰∏çË¶ÅÊãºÊé•ÊØè‰∏™ trialÔºåÂõ†‰∏∫ later evaluation ÊòØÈÄê trial ËØÑ‰º∞ performance„ÄÇ\n",
    "\n",
    "    return eeg_data_array, env_data_array\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "4b0a0d17",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_windows(eeg, env, window_len, Fs, null_model=False):\n",
    "    \"\"\"\n",
    "    Returns Windows of eeg and env to evaluate\n",
    "\n",
    "    Args:\n",
    "        eeg (list): eeg_data each element is (n_channels, n_samples)\n",
    "        env (list): env_data each element is (1, n_samples,)\n",
    "        window_len (float): window_len in seconds\n",
    "        Fs (float): sampling frequency\n",
    "\n",
    "    Returns:\n",
    "        tuple: eeg_windows, env_windows\n",
    "    \"\"\"\n",
    "    eeg_windows = []\n",
    "    env_windows = []\n",
    "    step_size = window_len * Fs\n",
    "\n",
    "    for i in range(len(eeg)):\n",
    "        eeg_trial = eeg[i]\n",
    "        env_trial = env[i]\n",
    "\n",
    "        if null_model:\n",
    "            # offset = int(env[0].shape[1] / 3)\n",
    "            # env_trial = np.roll(env_trial, offset, axis=1)\n",
    "            # ÈöèÊú∫ÂÅèÁßªÔºàËá≥Â∞ëÂÅèÁßª 20% ÈÅøÂÖçÂ§™Â∞èÔºâ\n",
    "            max_shift = int(env_trial.shape[1] * 0.8)\n",
    "            offset = np.random.randint(int(env_trial.shape[1]*0.2), max_shift)\n",
    "            env_trial = np.roll(env_trial, offset, axis=1)\n",
    "        \n",
    "        num_samples = eeg_trial.shape[1]\n",
    "        for start in range(0, num_samples - step_size + 1, step_size):\n",
    "            end = start + step_size\n",
    "            eeg_windows.append(eeg_trial[:, start:end])\n",
    "            env_windows.append(env_trial[:, start:end])\n",
    "    return eeg_windows, env_windows"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a115f1f4",
   "metadata": {},
   "source": [
    "# 4. üóÇÔ∏è Split Trials into Train, Validation, and Test Sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7241b417-b174-4536-a34e-b69e54b14d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== ‚öôÔ∏è Ê≠£Âú®Â§ÑÁêÜÁ™óÂè£Â§ßÂ∞è: 1 Áßí ========\n",
      "==================================================\n",
      "üöÄ Ê≠£Âú®Â§ÑÁêÜÂèÇ‰∏éËÄÖÔºö301\n",
      "==================================================\n",
      "Âä†ËΩΩ 301 ÂêéÁöÑÊÄª Trial Êï∞: 15\n",
      "Train Shapes: EEG=(31, 121570), ENV=(1, 121570)\n",
      "fitting entered\n",
      "Checking inputs...\n",
      "Formatting data matrix...\n",
      "Calculating coefficients...\n",
      "fitting entered\n",
      "Checking inputs...\n",
      "Formatting data matrix...\n",
      "Calculating coefficients...\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "cannot reshape array of size 0 into shape (992,1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[63], line 84\u001b[0m\n\u001b[1;32m     82\u001b[0m X \u001b[38;5;241m=\u001b[39m eeg_test_windows[i]\u001b[38;5;241m.\u001b[39mT\n\u001b[1;32m     83\u001b[0m y_true \u001b[38;5;241m=\u001b[39m env_test_windows[i]\n\u001b[0;32m---> 84\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mridge\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m   \u001b[38;5;66;03m# shape: (samples,)\u001b[39;00m\n\u001b[1;32m     85\u001b[0m r, _ \u001b[38;5;241m=\u001b[39m pearsonr(y_pred\u001b[38;5;241m.\u001b[39mflatten(), y_true\u001b[38;5;241m.\u001b[39mflatten())\n\u001b[1;32m     87\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mÂΩìÂâçsubjectÁöÑreconstruction value\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mr\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/Desktop/FAU/3-semester/audio-computer/models/ridge.py:136\u001b[0m, in \u001b[0;36mRidge.predict\u001b[0;34m(self, X, best_alpha)\u001b[0m\n\u001b[1;32m    134\u001b[0m     predictions \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_output_features, n_times))\n\u001b[1;32m    135\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m j \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_output_features):\n\u001b[0;32m--> 136\u001b[0m         preds \u001b[38;5;241m=\u001b[39m lagged_matrix \u001b[38;5;241m@\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef_\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbest_alpha_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mj\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnum_lags\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mn_input_features\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    137\u001b[0m         predictions[j] \u001b[38;5;241m=\u001b[39m preds\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m predictions\n",
      "\u001b[0;31mValueError\u001b[0m: cannot reshape array of size 0 into shape (992,1)"
     ]
    }
   ],
   "source": [
    "from sklearn import model_selection\n",
    "from scipy.stats import pearsonr\n",
    "\n",
    "\n",
    "initial_subjects = list(range(301, 316))\n",
    "trials = list(range(1,16))\n",
    "\n",
    "\n",
    "# ÂÆö‰πâÊâÄÊúâÁ™óÂè£ÈïøÂ∫¶ (Áßí)\n",
    "window_lengths = [1, 2, 5, 10, 20] \n",
    "\n",
    "# ÂÆö‰πâÊ®°ÂûãÂ∏∏Èáè\n",
    "alphas = np.logspace(-7, -4, 15)\n",
    "tmin, tmax = -0.25, 0.0\n",
    "start_lag = int(np.floor(tmin * Fs))\n",
    "end_lag = int(np.ceil(tmax * Fs))\n",
    "\n",
    "# Áî®‰∫éÂ≠òÂÇ®ÊâÄÊúâÁ™óÂè£ÈïøÂ∫¶ÁªìÊûúÁöÑÂàóË°®\n",
    "all_window_results = []\n",
    "\n",
    "# === Â§ñÂ±ÇÂæ™ÁéØÔºöÈÅçÂéÜÊâÄÊúâÁ™óÂè£Â§ßÂ∞è (Step 5) ===\n",
    "for win_len in window_lengths:\n",
    "    print(f\"\\n======== ‚öôÔ∏è Ê≠£Âú®Â§ÑÁêÜÁ™óÂè£Â§ßÂ∞è: {win_len} Áßí ========\")\n",
    "    # ÊØèÊ¨°Êñ∞Á™óÂè£Â§ßÂ∞èÊó∂ÔºåÈáçÊñ∞ÂàùÂßãÂåñÂàÜÊï∞ÂàóË°®\n",
    "    all_subjects_accuracy = [] \n",
    "    all_subjects_accuracy_null = []\n",
    "    \n",
    "    # --- ‰∏ªÂæ™ÁéØÔºöÈÅçÂéÜÊØè‰∏™ÂèÇ‰∏éËÄÖ ---\n",
    "    for subject_id in initial_subjects:\n",
    "        print(f\"==================================================\")\n",
    "        print(f\"üöÄ Ê≠£Âú®Â§ÑÁêÜÂèÇ‰∏éËÄÖÔºö{subject_id}\")\n",
    "        print(f\"==================================================\")\n",
    "        \n",
    "        # === 1. Âä†ËΩΩÂíåÂàÜÂâ≤Êï∞ÊçÆ ===\n",
    "        \n",
    "        # Âä†ËΩΩÂΩìÂâç subject ÁöÑÂÖ®ÈÉ® EEG Âíå Envelope Êï∞ÊçÆ\n",
    "        eeg, env = load_subject_data(subject_id, ica=False) \n",
    "        print(f\"Âä†ËΩΩ {subject_id} ÂêéÁöÑÊÄª Trial Êï∞: {len(eeg)}\")\n",
    "        \n",
    "        #inter-trial split\n",
    "        train_ind, test_ind = sklearn.model_selection.train_test_split(trials, test_size=0.4, random_state=42)\n",
    "        val_ind, test_ind = sklearn.model_selection.train_test_split(test_ind, test_size=0.5, random_state=42)\n",
    "        \n",
    "        #get data\n",
    "        eeg_train, env_train = get_data_from_indices(eeg, env, train_ind)\n",
    "        eeg_val, env_val = get_data_from_indices(eeg, env, val_ind)\n",
    "        eeg_test, env_test = get_data_from_indices(eeg, env, test_ind, test=True)\n",
    "                \n",
    "        # üÜï ÂÖ≥ÈîÆËØäÊñ≠ÁÇπÔºöÊ£ÄÊü•Êï∞ÊçÆÊòØÂê¶‰∏∫Á©∫\n",
    "        if eeg_train.size == 0 or env_train.size == 0:\n",
    "            print(f\"üö® Ë≠¶Âëä: Subject {subject_id} ÁöÑËÆ≠ÁªÉÊï∞ÊçÆ‰∏∫Á©∫ (size=0)ÔºÅË∑≥ËøáËØ• Subject„ÄÇ\")\n",
    "            continue # Ë∑≥ËøáÂΩìÂâç subject ÁöÑÂêéÁª≠Ê≠•È™§\n",
    "            \n",
    "        print(f\"Train Shapes: EEG={eeg_train.shape}, ENV={env_train.shape}\")\n",
    "        \n",
    "        # === 2. Ê®°ÂûãÂàùÂßãÂåñÂíåËÆ≠ÁªÉ ===\n",
    "        ridge = Ridge(alpha=alphas, start_lag=start_lag, end_lag=end_lag)\n",
    "        \n",
    "        # Â∞ùËØï fit\n",
    "        try:\n",
    "            ridge.fit(eeg_train.T, env_train.T)\n",
    "        except Exception as e:\n",
    "            print(f\"‚ùå ÈîôËØØ: Subject {subject_id} Ê®°ÂûãËÆ≠ÁªÉÂ§±Ë¥•: {e}\")\n",
    "            continue # Ë∑≥ËøáÂΩìÂâç subject\n",
    "\n",
    "        \n",
    "        # b. ËÆ≠ÁªÉÊ®°Âûã \n",
    "    \n",
    "        ridge.fit(eeg_train.T, env_train.T)\n",
    "        hasattr(ridge, \"n_input_features\") #ÁúãfitÊòØÂê¶ËøêË°åÊàêÂäü\n",
    "    \n",
    "        \n",
    "        # c. ÊúÄÁªàÊµãËØïÔºà‰ΩøÁî®ÊúÄ‰Ω≥ alpha Âú® test ÈõÜ‰∏äËÆ°ÁÆóÈáçÊûÑÂáÜÁ°ÆÁéáÔºâ\n",
    "        win_len = 10\n",
    "        # chunk test data into windows\n",
    "        eeg_test_windows, env_test_windows = get_data_windows(eeg_test, env_test, window_len=win_len, Fs=Fs)\n",
    "        \n",
    "        # Evaluate on the test windows\n",
    "    \n",
    "        test_scores = []\n",
    "        for i in range(len(eeg_test_windows)):\n",
    "            X = eeg_test_windows[i].T\n",
    "            y_true = env_test_windows[i]\n",
    "            y_pred = ridge.predict(X)   # shape: (samples,)\n",
    "            r, _ = pearsonr(y_pred.flatten(), y_true.flatten())\n",
    "    \n",
    "            print(f\"\\nÂΩìÂâçsubjectÁöÑreconstruction value{r}\")\n",
    "        \n",
    "            test_scores.append(r)\n",
    "        \n",
    "        # === 3. ÁªìÊûúÂ≠òÂÇ® ===\n",
    "        # Â∞ÜËØ• subject ÁöÑÊúÄÁªàÂáÜÁ°ÆÁéáÔºà‰æãÂ¶ÇÔºåÈáçÊûÑÁõ∏ÂÖ≥Á≥ªÊï∞ rÔºâÊ∑ªÂä†Âà∞ÂàóË°®‰∏≠\n",
    "        all_subjects_accuracy.append(test_scores)\n",
    "    \n",
    "        # === 4. Noise Control === \n",
    "        # Generate null distribution by shifting env data\n",
    "        env_test_windows_null = get_data_windows(eeg_test, env_test, window_len=win_len, Fs=Fs, null_model=True)[1]\n",
    "        null_scores = []\n",
    "        for i in range(len(eeg_test_windows)):\n",
    "            X = eeg_test_windows[i].T\n",
    "            # ‰ΩøÁî®Èîô‰ΩçÁöÑÂåÖÁªúËøõË°åËØÑÂàÜ\n",
    "            y_null_true = env_test_windows_null[i] \n",
    "            \n",
    "            # ‰ΩøÁî®ËÆ≠ÁªÉÂ•ΩÁöÑÊ®°ÂûãËøõË°åÈ¢ÑÊµã\n",
    "            y_pred = ridge.predict(X) \n",
    "            # ËÆ°ÁÆóÈ¢ÑÊµãÂÄº‰∏éÈîô‰ΩçÂåÖÁªúÁöÑÁõ∏ÂÖ≥Á≥ªÊï∞\n",
    "            r_null, _ = pearsonr(y_pred.flatten(), y_null_true.flatten())\n",
    "            null_scores.append(r_null)\n",
    "        test_scores_null_a = np.array(null_scores).flatten()  #make sureËøΩÂä†Âà∞ÂàóË°®ÂâçÊòØ‰∏Ä‰∏™Âπ≤ÂáÄÁöÑ 1D Êï∞ÁªÑ\n",
    "        all_test_scores_null.append(test_scores_null_a)\n",
    "        print(f\"‚úÖ ÂèÇ‰∏éËÄÖ {subject_id} Â§ÑÁêÜÂÆåÊàê„ÄÇ\")\n",
    "\n",
    "    # ----------------------------------------------------\n",
    "            # Â§ñÂ±ÇÂæ™ÁéØÁªìÊùüÂêéÁöÑËÅöÂêàÂíåÁªüËÆ° (ÈíàÂØπÂΩìÂâç win_len)\n",
    "    # ----------------------------------------------------\n",
    "    \n",
    "    # 1. Â±ïÂπ≥ÊâÄÊúâÂàÜÊï∞ÁªÑÂêà\n",
    "    all_scores_flattened = np.concatenate(all_subjects_accuracy)\n",
    "    all_null_scores_flattened = np.concatenate(all_subjects_accuracy_null)\n",
    "    \n",
    "    # 2. ËÆ°ÁÆóÂΩìÂâçÁ™óÂè£Â§ßÂ∞èÁöÑÁæ§‰ΩìÂπ≥Âùá r ÂíåÊ†áÂáÜÂ∑Æ\n",
    "    mean_r = np.mean(all_scores_flattened)\n",
    "    std_r = np.std(all_scores_flattened)\n",
    "    \n",
    "    # 3. ËÆ°ÁÆóÊòæËëóÊÄß (Wilcoxon Test)\n",
    "    wilcoxon_results = pg.wilcoxon(all_scores_flattened, all_null_scores_flattened, alternative='greater')\n",
    "    p_val = wilcoxon_results['p-val'].values[0]\n",
    "\n",
    "    print(f\"‚úÖ Á™óÂè£ {win_len} Áßí -> Âπ≥Âùá r: {mean_r:.3f}, Ê†áÂáÜÂ∑Æ: {std_r:.3f}, P ÂÄº: {p_val:.2e}\")\n",
    "    \n",
    "    # 4. Â≠òÂÇ®ÁªìÊûúÔºåÁî®‰∫éÊúÄÁªàÁªòÂõæ\n",
    "    all_window_results.append({\n",
    "        'window_len': win_len,\n",
    "        'mean_r': mean_r,\n",
    "        'std_r': std_r,\n",
    "        'p_val': p_val\n",
    "    })\n",
    "    \n",
    "    # ----------------------------------------------------\n",
    "    # üÜï ÂèØËßÜÂåñÔºöÁªòÂà∂ Test Scores vs Null Distribution Boxplot\n",
    "    # ----------------------------------------------------\n",
    "    if win_len == window_lengths[0]: # Âè™ÈúÄË¶ÅÂØπÁ¨¨‰∏Ä‰∏™Á™óÂè£ÈïøÂ∫¶ËøêË°å‰∏ÄÊ¨° BoxplotÔºåÂàÜÊûênoise controlÁöÑÊó∂ÂÄôÊéßÂà∂Á™óÂè£ÈïøÂ∫¶‰∏çÂèò\n",
    "        print(\"\\n--- ÁªòÂà∂ Test Scores vs Null Distribution (Áî®‰∫éÊ®°ÂûãÈ™åËØÅ) ---\")\n",
    "        \n",
    "        # Â∞ÜÂ±ïÂπ≥ÂêéÁöÑÂàÜÊï∞ËΩ¨Êç¢‰∏∫ Pandas DataFrame ÁöÑÈïøÊ†ºÂºè\n",
    "        data = {\n",
    "            'Reconstruction Score (r)': np.concatenate([all_scores_flattened, all_null_scores_flattened]),\n",
    "            'Distribution Type': (\n",
    "                ['Test Scores'] * len(all_scores_flattened) + \n",
    "                ['Null Scores'] * len(all_null_scores_flattened)\n",
    "            )\n",
    "        }\n",
    "        df = pd.DataFrame(data)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(7,5))\n",
    "        \n",
    "        # ‰ΩøÁî® Boxplot ÂèØËßÜÂåñ‰∏§‰∏™ÂàÜÂ∏É\n",
    "        sns.boxplot(x='Distribution Type', y='Reconstruction Score (r)', data=df, ax=ax, palette=['#1f77b4', '#ff7f0e'])\n",
    "        \n",
    "        # Ê∑ªÂä†Èõ∂Á∫ø\n",
    "        ax.axhline(0, color='k', linestyle='dashed', linewidth=1) \n",
    "        \n",
    "        # Ê†áÈ¢òÂíåÊ†áÁ≠æ\n",
    "        ax.set_title(f'Test Scores vs Null Distribution ({win_len}s Window)', fontsize=14)\n",
    "        ax.set_xlabel('') # xËΩ¥Ê†áÁ≠æÈÄöÂ∏∏‰∏çÈúÄË¶ÅÔºåÂõ†‰∏∫Âõæ‰æãÂ∑≤ÁªèËØ¥Êòé\n",
    "        ax.set_ylabel('Reconstruction Score (r)')\n",
    "        \n",
    "        plt.show()\n",
    "        \n",
    "        # È¢ùÂ§ñÊâìÂç∞ÊòæËëóÊÄßÁªìÊûú (P ÂÄº)\n",
    "        print(f\"ÁªüËÆ°ÊòæËëóÊÄß (Wilcoxon P ÂÄº): {p_val:.2e}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------\n",
    "# ÊúÄÁªàÊ≠•È™§ÔºöÁªòÂà∂ Window Size ÊØîËæÉÂõæ (Step 5)\n",
    "# ----------------------------------------------------\n",
    "# Â∞ÜÊâÄÊúâÁ™óÂè£ÁªìÊûúËΩ¨Êç¢‰∏∫ DataFrame\n",
    "df_window = pd.DataFrame(all_window_results)\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "\n",
    "# ‰ΩøÁî® Errorbar ÁªòÂà∂ r ÂÄºÈöèÁ™óÂè£ÈïøÂ∫¶ÁöÑÂèòÂåñÔºåÂπ∂Áî®Ê†áÂáÜÂ∑Æ‰Ωú‰∏∫ËØØÂ∑ÆÊ£í\n",
    "ax.errorbar(df_window['window_len'], df_window['mean_r'], \n",
    "            yerr=df_window['std_r'], fmt='-o', color='b', capsize=5, label='Mean $r \\pm 1$ SD')\n",
    "\n",
    "ax.set_xscale('log') # xËΩ¥‰ΩøÁî®ÂØπÊï∞ÂàªÂ∫¶ÔºåÂõ†‰∏∫Á™óÂè£ÈïøÂ∫¶ÈùûÁ∫øÊÄßÂèòÂåñ\n",
    "\n",
    "ax.set_xlabel('Window Length (seconds, log scale)')\n",
    "ax.set_ylabel('Mean Reconstruction Score (r)')\n",
    "ax.set_title('Effect of Window Length on Reconstruction Score', fontsize=16)\n",
    "\n",
    "# Ê∑ªÂä†Èõ∂Á∫ø\n",
    "ax.axhline(0, color='k', linestyle='dashed', linewidth=1)\n",
    "\n",
    "# ËÆæÁΩÆxËΩ¥ÂàªÂ∫¶ÔºåÂè™ÊòæÁ§∫Êàë‰ª¨ÊµãËØïÁöÑÈïøÂ∫¶\n",
    "ax.set_xticks(df_window['window_len'])\n",
    "ax.set_xticklabels(df_window['window_len']) \n",
    "\n",
    "plt.grid(True, which=\"both\", ls=\"--\", alpha=0.5)\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(\"\\n--- ÊâÄÊúâÁ™óÂè£ÈïøÂ∫¶ÁöÑÁªüËÆ°ÊëòË¶Å ---\")\n",
    "print(df_window)\n",
    "    \n",
    "    # # --- Âæ™ÁéØÁªìÊùüÂêéÔºåËÆ°ÁÆóÁæ§‰ΩìÂπ≥ÂùáÁªìÊûú ---\n",
    "    # population_avg_r = np.mean(all_subjects_accuracy)\n",
    "    # print(f\"\\nÁæ§‰ΩìÂπ≥ÂùáÈáçÊûÑÂáÜÁ°ÆÁéá r = {population_avg_r:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f80a984",
   "metadata": {},
   "source": [
    "# 8. üèÅ Get Final Results on the Test Set\n",
    "\n",
    "Finally, we can evaluate our chosen model on the **test set**. This step is crucial as it gives us insight into how well the model **generalized** to completely new, unseen data.\n",
    "\n",
    "\n",
    "\n",
    "### Chunking the Data for a Robust Score\n",
    "\n",
    "To get more valid data, we don't just get one single score for the entire test set. Instead, we **chunk the test data into smaller windows**.\n",
    "\n",
    "* This allows us to get multiple reconstruction scores (one for each chunk).\n",
    "* From these multiple scores, we can form a meaningful **distribution of results**, rather than relying on a single, potentially noisy, value.\n",
    "\n",
    "Let's start with a **10-second decision window**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "141fbeb2",
   "metadata": {},
   "source": [
    "# 9. üìä Compare Test Scores Against a Null Distribution\n",
    "\n",
    "As we did for the forward model, we must compare our reconstruction scores against a **null distribution**. This tells us if our model's performance is statistically significant, or if it could have just happened by chance.\n",
    "\n",
    "We generate this null distribution by:\n",
    "1.  **Shifting** the envelope data relative to the EEG data.\n",
    "2.  **Re-calculating** the reconstruction scores with this \"broken\" data.\n",
    "\n",
    "This shift **destroys the true phase relationship** between the brain signals and the audio. The resulting scores show us what performance looks like when there is no real connection.\n",
    "\n",
    "\n",
    "\n",
    "> **An Analogy: Attention Decoding**\n",
    ">\n",
    "> For an attention decoding task, a common way to create a null distribution is to use the envelope of the *distractor* (unattended) speaker and run the same analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "7f0ed311",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ÂÅáËÆæ all_subjects_accuracy ÊòØÊâÄÊúâÂèÇ‰∏éËÄÖ scores Êï∞ÁªÑÁöÑÂàóË°®\n",
    "all_scores_flattened = np.concatenate(all_subjects_accuracy)\n",
    "all_null_scores_flattened = np.concatenate(all_test_scores_null) # ÂÅáËÆæÊÇ®Êúâ‰∏Ä‰∏™Á±ª‰ººÁöÑ null ÂàóË°®\n",
    "\n",
    "# Â∞Ü‰∏§ÁßçÂàÜÊï∞ÁªÑÂêàÊàê‰∏Ä‰∏™Â≠óÂÖ∏/DataFrame\n",
    "scores_dict = {\n",
    "    'Test Scores': all_scores_flattened,\n",
    "    'Null Scores': all_null_scores_flattened\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "491050b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x30c9a3a90>"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 500x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "sns.boxplot(data=scores_dict, ax=ax)\n",
    "ax.set_ylabel('Reconstruction Score (r)')\n",
    "ax.set_title('Test Scores vs Null Distribution', fontsize=14)\n",
    "ax.hlines(0, -0.5, 1.5, colors='k', linestyles='dashed')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "c6d539e7-9df8-4cd1-b2d0-35f4ba7c83a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EEG_train shape: (31, 121570)\n",
      "env_train shape: (1, 121570)\n",
      "EEG_test_window shape: (31, 1280)\n",
      "env_test_window shape: (1, 1280)\n",
      "Correlation between true and null envelope: 0.08131715635095728\n"
     ]
    }
   ],
   "source": [
    "print(\"EEG_train shape:\", eeg_train.shape)\n",
    "print(\"env_train shape:\", env_train.shape)\n",
    "\n",
    "print(\"EEG_test_window shape:\", eeg_test_windows[0].shape)\n",
    "print(\"env_test_window shape:\", env_test_windows[0].shape)\n",
    "\n",
    "print(\"Correlation between true and null envelope:\",\n",
    "      np.corrcoef(env_test_windows[0], env_test_windows_null[0])[0,1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "95741ff1-d9b0-4f54-a3f2-40837956c4a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Scores ÈïøÂ∫¶: 495\n",
      "Null Scores ÈïøÂ∫¶: 495\n"
     ]
    }
   ],
   "source": [
    "print(f\"Test Scores ÈïøÂ∫¶: {len(all_scores_flattened)}\")\n",
    "print(f\"Null Scores ÈïøÂ∫¶: {len(all_null_scores_flattened)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0779767c",
   "metadata": {},
   "source": [
    "Here, we test the statistical significance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "41e4561b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>W-val</th>\n",
       "      <th>alternative</th>\n",
       "      <th>p-val</th>\n",
       "      <th>RBC</th>\n",
       "      <th>CLES</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Wilcoxon</th>\n",
       "      <td>27678.0</td>\n",
       "      <td>two-sided</td>\n",
       "      <td>3.512654e-26</td>\n",
       "      <td>0.549071</td>\n",
       "      <td>0.69821</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            W-val alternative         p-val       RBC     CLES\n",
       "Wilcoxon  27678.0   two-sided  3.512654e-26  0.549071  0.69821"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pg.wilcoxon(all_scores_flattened, all_null_scores_flattened)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b02fdb0",
   "metadata": {},
   "source": [
    "# 10. ‚è±Ô∏è Study the Effect of Window Size\n",
    "\n",
    "Here, we want to see how different window sizes (or \"chunk lengths\") affect the reconstruction scores.\n",
    "\n",
    "\n",
    "\n",
    "Intuitively, a longer window might provide more information and lead to a better score, but it also results in fewer samples to average over. A shorter window gives us more samples, but each one might be less reliable.\n",
    "\n",
    "To find the \"sweet spot,\" we will create and evaluate test sets using several different window lengths."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8e8bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "window_lengths = [1, 2, 5, 10, 20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b25934f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Get a list of (eeg, env) pairs for each window length\n",
    "windowed_data = [get_data_windows(eeg_test, env_test, window_len=w, Fs=Fs) for w in window_lengths]\n",
    "\n",
    "# 2. \"Unzip\" the list of pairs into two separate lists\n",
    "eeg_diff_windows, env_diff_windows = zip(*windowed_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "622b88a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Window Length: 1 sec - Mean Reconstruction Score: 0.1024 ¬± 0.3669\n",
      "Window Length: 3 sec - Mean Reconstruction Score: 0.1134 ¬± 0.2096\n",
      "Window Length: 5 sec - Mean Reconstruction Score: 0.1054 ¬± 0.1648\n",
      "Window Length: 10 sec - Mean Reconstruction Score: 0.1109 ¬± 0.1247\n",
      "Window Length: 20 sec - Mean Reconstruction Score: 0.1131 ¬± 0.0905\n",
      "Window Length: 30 sec - Mean Reconstruction Score: 0.1106 ¬± 0.0602\n",
      "Window Length: 45 sec - Mean Reconstruction Score: 0.1094 ¬± 0.0607\n",
      "Window Length: 60 sec - Mean Reconstruction Score: 0.1031 ¬± 0.0248\n"
     ]
    }
   ],
   "source": [
    "windowed_mean_scores = []\n",
    "windowed_std_scores = []\n",
    "for i, w in enumerate(window_lengths):\n",
    "    eeg_windows = eeg_diff_windows[i]\n",
    "    env_windows = env_diff_windows[i]\n",
    "    test_scores_w = [ridge.score(np.array(eeg_windows[j]).T, np.array(env_windows[j]).T) for j in range(len(eeg_windows))]\n",
    "    test_scores_w = np.array(test_scores_w).flatten()\n",
    "\n",
    "    windowed_mean_scores.append(np.mean(test_scores_w))\n",
    "    windowed_std_scores.append(np.std(test_scores_w))\n",
    "\n",
    "    print(f'Window Length: {w} sec - Mean Reconstruction Score: {np.mean(test_scores_w):.4f} ¬± {np.std(test_scores_w):.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "9f0f39d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 1.0, 'Effect of Window Length on Reconstruction Score')"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(5,4))\n",
    "ax.errorbar(window_lengths, windowed_mean_scores, yerr=windowed_std_scores, marker='o', capsize=5)\n",
    "ax.set_xlabel('Window Length (seconds)')\n",
    "ax.set_ylabel('Mean Reconstruction Score (r)')\n",
    "ax.set_title('Effect of Window Length on Reconstruction Score', fontsize=14)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
